{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16523,
     "status": "ok",
     "timestamp": 1619555965242,
     "user": {
      "displayName": "Chuan Chen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjGNZ_BC0raiaLxFCSgR1dppBgMgjY4TPSe81Bz=s64",
      "userId": "01488084844237739692"
     },
     "user_tz": 240
    },
    "id": "4jzb7Vzy17VF",
    "outputId": "88d79522-774d-4e7b-f734-33de80fa7388"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16515,
     "status": "ok",
     "timestamp": 1619555965243,
     "user": {
      "displayName": "Chuan Chen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjGNZ_BC0raiaLxFCSgR1dppBgMgjY4TPSe81Bz=s64",
      "userId": "01488084844237739692"
     },
     "user_tz": 240
    },
    "id": "VeuA8oYo2NIP",
    "outputId": "100347dd-a8e7-426f-8705-a5eab2e8dd3f"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/content/drive/My Drive/Carlos_Research_2')\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16647,
     "status": "ok",
     "timestamp": 1619555965383,
     "user": {
      "displayName": "Chuan Chen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjGNZ_BC0raiaLxFCSgR1dppBgMgjY4TPSe81Bz=s64",
      "userId": "01488084844237739692"
     },
     "user_tz": 240
    },
    "id": "vi9jNO9xFfAC",
    "outputId": "08fa3c43-69c6-4527-df0a-54b6ab4925ee"
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fPjjUZHwFgSM"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5068,
     "status": "ok",
     "timestamp": 1619555973679,
     "user": {
      "displayName": "Chuan Chen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjGNZ_BC0raiaLxFCSgR1dppBgMgjY4TPSe81Bz=s64",
      "userId": "01488084844237739692"
     },
     "user_tz": 240
    },
    "id": "fyFU512jNL_c",
    "outputId": "28a6b98f-8af9-454d-bea8-cde7195ef839"
   },
   "outputs": [],
   "source": [
    "!pip install sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 7614,
     "status": "ok",
     "timestamp": 1619555977910,
     "user": {
      "displayName": "Chuan Chen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjGNZ_BC0raiaLxFCSgR1dppBgMgjY4TPSe81Bz=s64",
      "userId": "01488084844237739692"
     },
     "user_tz": 240
    },
    "id": "QuZ4G8DmFhOJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   #if like me you do not have a lot of memory in your GPU\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\" #then these two lines force keras to use your CPU\n",
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Flatten, Conv3D, MaxPooling3D, Dropout, BatchNormalization, \\\n",
    "LeakyReLU, Conv2DTranspose, ReLU, Reshape, Concatenate, Input\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.image import psnr\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import random\n",
    "import itertools\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import sparse\n",
    "from EMDataGenerator import EMDataGenerator\n",
    "  # not scipy sparse because that is not how michael encoded it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 6067,
     "status": "ok",
     "timestamp": 1619555977920,
     "user": {
      "displayName": "Chuan Chen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjGNZ_BC0raiaLxFCSgR1dppBgMgjY4TPSe81Bz=s64",
      "userId": "01488084844237739692"
     },
     "user_tz": 240
    },
    "id": "D980xsVETHGA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 3519232288690082470\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 814380144862555734\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5175092192\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 13062917530469662014\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 2116889883881068343\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-cZn30ncTHPc"
   },
   "source": [
    "# load data - small size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 373,
     "status": "ok",
     "timestamp": 1619555998610,
     "user": {
      "displayName": "Chuan Chen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjGNZ_BC0raiaLxFCSgR1dppBgMgjY4TPSe81Bz=s64",
      "userId": "01488084844237739692"
     },
     "user_tz": 240
    },
    "id": "4y7hZdmaDzvP",
    "outputId": "b4a22691-3b41-4040-bfd9-806b30f1cd24"
   },
   "outputs": [],
   "source": [
    "!ls em_data_10a_2channels/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1095,
     "status": "ok",
     "timestamp": 1619556013527,
     "user": {
      "displayName": "Chuan Chen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjGNZ_BC0raiaLxFCSgR1dppBgMgjY4TPSe81Bz=s64",
      "userId": "01488084844237739692"
     },
     "user_tz": 240
    },
    "id": "dmuOuuF7THPc"
   },
   "outputs": [],
   "source": [
    "with open(r\"em_data_10a_2channels/X_list_10a_2channel.pkl\", 'rb') as f:\n",
    "  # despite the name, it has dimensions 84x54x98\n",
    "  X_3d = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 729,
     "status": "ok",
     "timestamp": 1619556022619,
     "user": {
      "displayName": "Chuan Chen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjGNZ_BC0raiaLxFCSgR1dppBgMgjY4TPSe81Bz=s64",
      "userId": "01488084844237739692"
     },
     "user_tz": 240
    },
    "id": "bwyRxc58THPc"
   },
   "outputs": [],
   "source": [
    "with open(r\"em_data_10a_2channels/y_list_10a_2channel.pkl\", 'rb') as f:\n",
    "  y_2d = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 232,
     "status": "ok",
     "timestamp": 1619556024792,
     "user": {
      "displayName": "Chuan Chen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjGNZ_BC0raiaLxFCSgR1dppBgMgjY4TPSe81Bz=s64",
      "userId": "01488084844237739692"
     },
     "user_tz": 240
    },
    "id": "CFrjsJLpTHPd",
    "outputId": "77ef6c99-1534-4dde-9c0b-220cf273af9e"
   },
   "outputs": [],
   "source": [
    "print(len(X_3d))\n",
    "print(type(X_3d))\n",
    "print(X_3d[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 258,
     "status": "ok",
     "timestamp": 1619556029152,
     "user": {
      "displayName": "Chuan Chen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjGNZ_BC0raiaLxFCSgR1dppBgMgjY4TPSe81Bz=s64",
      "userId": "01488084844237739692"
     },
     "user_tz": 240
    },
    "id": "sqE8Cu4kTHPd",
    "outputId": "419ad9de-0f82-4d0e-f719-2c18661aeb0d"
   },
   "outputs": [],
   "source": [
    "print(len(y_2d))\n",
    "print(type(y_2d))\n",
    "print(y_2d[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 245,
     "status": "ok",
     "timestamp": 1619556041054,
     "user": {
      "displayName": "Chuan Chen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjGNZ_BC0raiaLxFCSgR1dppBgMgjY4TPSe81Bz=s64",
      "userId": "01488084844237739692"
     },
     "user_tz": 240
    },
    "id": "X2wNASOXTHPd"
   },
   "outputs": [],
   "source": [
    "# every element in the X_3d list is a sparse matrix, convert it to a 3D numpy array\n",
    "# takes too large of a memory, only process the first 3 matrix\n",
    "X_array = []\n",
    "for i in range(3):\n",
    "  X_array.append(sparse.COO.todense(X_3d[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 242,
     "status": "ok",
     "timestamp": 1619556120587,
     "user": {
      "displayName": "Chuan Chen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjGNZ_BC0raiaLxFCSgR1dppBgMgjY4TPSe81Bz=s64",
      "userId": "01488084844237739692"
     },
     "user_tz": 240
    },
    "id": "meLmZucoESNU",
    "outputId": "812bb881-36a9-49eb-d5ae-1f7793025055"
   },
   "outputs": [],
   "source": [
    "X_array[i].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 257,
     "status": "ok",
     "timestamp": 1619556151113,
     "user": {
      "displayName": "Chuan Chen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjGNZ_BC0raiaLxFCSgR1dppBgMgjY4TPSe81Bz=s64",
      "userId": "01488084844237739692"
     },
     "user_tz": 240
    },
    "id": "pO2iPXQ2THPe"
   },
   "outputs": [],
   "source": [
    "# change X to be an array of input shape (#_samples, x, y, z)\n",
    "# change y to be an array of output shape (#_samples, x, y)\n",
    "# also crop them to be squares/cubes\n",
    "# but for the 3D, do not take the canter on the z-dim, take the front because those are closer to the camera\n",
    "\n",
    "X_train = np.zeros(shape=(3, 32, 32, 32, 2))\n",
    "y_train = np.zeros(shape=(3,32,32,1))\n",
    "  # must add a channel dimension even if we only have 1 channel\n",
    "  # the keras model require the extra channel dimension to do 2d and 3d convolutions\n",
    "\n",
    "for i in range(3):\n",
    "  X_train[i, :, :, :, :] = X_array[i][26:58, 11:43, 0:32,:]\n",
    "\n",
    "for i in range(3):\n",
    "  y_train[i, :, :, 0]  = y_2d[i][11:43, 26:58]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 244,
     "status": "ok",
     "timestamp": 1619556155568,
     "user": {
      "displayName": "Chuan Chen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjGNZ_BC0raiaLxFCSgR1dppBgMgjY4TPSe81Bz=s64",
      "userId": "01488084844237739692"
     },
     "user_tz": 240
    },
    "id": "5Y6HUAeWTHPe",
    "outputId": "f1830c6e-6f08-46e7-a2c0-728c7b3f5d86"
   },
   "outputs": [],
   "source": [
    "np.unique(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 181,
     "status": "ok",
     "timestamp": 1619556156838,
     "user": {
      "displayName": "Chuan Chen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjGNZ_BC0raiaLxFCSgR1dppBgMgjY4TPSe81Bz=s64",
      "userId": "01488084844237739692"
     },
     "user_tz": 240
    },
    "id": "5-b1BAxIWdst",
    "outputId": "1e719249-bec1-4aa3-87e1-4aa13a711f93"
   },
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_filename = '../em_data/em_data_32x32_043021/X_list_32x32x32.pkl'\n",
    "y_filename = '../em_data/em_data_32x32_043021/y_list_full_32x32.pkl'\n",
    "defocus_filename = '../em_data/em_data_32x32_043021/defocus_list_32x32.pkl'\n",
    "\n",
    "# This is a bit confusing, but train and validation are randomly selected from train_val_range so that \n",
    "# validation is just new defocus views of lattices we've seen\n",
    "# Test is held out lattices, all of test_range.\n",
    "train_val_range = [0.,0.9]\n",
    "train_shuffle = [0.,0.9]\n",
    "val_shuffle = [0.9,1.]\n",
    "test_range = [0.9,1.]\n",
    "train_generator = EMDataGenerator(X_filename,y_filename,train_val_range,train_shuffle,5,defocus_filename)\n",
    "valid_generator = EMDataGenerator(X_filename,y_filename,train_val_range,val_shuffle,5,defocus_filename)\n",
    "test_generator = EMDataGenerator(X_filename,y_filename,test_range,None,5,defocus_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(5, 64, 64, 64, 2)\n",
      "(5, 9)\n",
      "(5, 64, 64, 1)\n",
      "0.0 1.2196909\n",
      "1880\n"
     ]
    }
   ],
   "source": [
    "X,y = train_generator[22]\n",
    "print(len(X))\n",
    "print(X[0].shape)\n",
    "print(X[1].shape)\n",
    "print(y.shape)\n",
    "print(y.min(),y.max())\n",
    "print(len(train_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding metrics\n",
    "Track PSNR and MSE through training (not sure why val_loss and val_mse_metric are not equal, but loss and mse_metric are equal...validation loss is calculated differently for some reason).\n",
    "These metrics are passed in to model.compile(metrics=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate training y pixel intensity range, for PSNR function\n",
    "y_range = np.array(train_generator.y).max() - np.array(train_generator.y).min()\n",
    "\n",
    "def psnr_metric(y_true,y_pred):\n",
    "    return psnr(y_true,y_pred,y_range)\n",
    "\n",
    "def mse_metric(y_true,y_pred):\n",
    "    return keras.losses.MSE(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lioa3qsOXHSB"
   },
   "source": [
    "# model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 239,
     "status": "ok",
     "timestamp": 1619556160814,
     "user": {
      "displayName": "Chuan Chen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjGNZ_BC0raiaLxFCSgR1dppBgMgjY4TPSe81Bz=s64",
      "userId": "01488084844237739692"
     },
     "user_tz": 240
    },
    "id": "wGNxV2wMtB01"
   },
   "outputs": [],
   "source": [
    "sample_shape = (64,64,64,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1625,
     "status": "ok",
     "timestamp": 1619556164042,
     "user": {
      "displayName": "Chuan Chen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjGNZ_BC0raiaLxFCSgR1dppBgMgjY4TPSe81Bz=s64",
      "userId": "01488084844237739692"
     },
     "user_tz": 240
    },
    "id": "LuuQ_5x_uD8m",
    "outputId": "9c21ed9d-d98a-4b3e-a034-3f351a42e30a"
   },
   "outputs": [],
   "source": [
    "def conditional_model(sample_shape=(32,32,32,2), defocus_1hot_shape = (9,)):\n",
    "  '''\n",
    "  takes in 3D input of shape (dim,dim,dim,2) and outputs a grey-scale 2-D image of shape (dim,dim,1).\n",
    "  dim should be an power of 2 integer\n",
    "  sample_shape:\n",
    "    the shape of 1 sample, should be (dim,dim,dim,2)\n",
    "  defocus_1hot_shape_shape:\n",
    "    the shape of 1 row of one-hot-endoed defocus parameter of the input sample, should be (#_unique_defocus-1, )\n",
    "  '''\n",
    "\n",
    "  dim = sample_shape[0]\n",
    "  f = int(32/(dim/32))\n",
    "    # the starting filter size\n",
    "\n",
    "  iter = int(np.log2(dim)) - 1\n",
    "    # takes one less iteration because we want the shape to stop at 2, not 1\n",
    "    # 4 for 32, 5 for 64, 6 for 128, 7 for 256\n",
    "\n",
    "  # Create the model\n",
    "  input_voxel = Input(shape=sample_shape)\n",
    "  defocus = Input(shape=defocus_1hot_shape, dtype='float32')\n",
    "  \n",
    "  # add first layer that takes in the input\n",
    "  encoder = Conv3D(filters=f, \n",
    "                  kernel_size=(4, 4, 4), \n",
    "                  strides=(2, 2, 2),\n",
    "                  padding='same', \n",
    "                      # `same` just means as long as even just the left most 1 column of your kernel is still in the sample matrix, you will use padding to fill the parts that ran over the matrix and finish that mapping\n",
    "                      # if you keep moving till you kernel does not overlap with your matrix at all we will stop and won't pad anymore\n",
    "                  use_bias=False,\n",
    "                  input_shape=sample_shape)(input_voxel)\n",
    "  # model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "  encoder = BatchNormalization(center=True, scale=True)(encoder)\n",
    "  encoder = LeakyReLU(alpha=0.2)(encoder)\n",
    "  # now the output should have shape (dim/2, dim/2, dim/2, f)\n",
    "\n",
    "  # add middel encoder layers\n",
    "  for i in range(1, iter): # 1~iter-1\n",
    "    encoder = Conv3D(filters=f*(2**i), \n",
    "                    kernel_size=(4, 4, 4), \n",
    "                    strides=(2, 2, 2),\n",
    "                    padding='same',\n",
    "                    use_bias=False)(encoder)\n",
    "    encoder = BatchNormalization(center=True, scale=True)(encoder)\n",
    "    encoder = LeakyReLU(alpha=0.2)(encoder)\n",
    "  \n",
    "  # now the output should have shape (2, 2, 2, f*(2**i))\n",
    "\n",
    "  # add latent layer\n",
    "  encoder = Conv3D(filters=100, \n",
    "                  kernel_size=(2, 2, 2), \n",
    "                  strides=(1, 1, 1),\n",
    "                  padding='valid',\n",
    "                  use_bias=False)(encoder)\n",
    "  encoder = LeakyReLU(alpha=0.2)(encoder)\n",
    "    # VALID : Don't apply any padding\n",
    "    # now the output should have shape (1, 1, 1, 100)\n",
    "\n",
    "  encoder = Reshape((1,1,100))(encoder)\n",
    "    # must reshape from a 3-D structure with 100 channels to a 2-D image having 100 channels\n",
    "    # so Conv2DTranspose can work properly\n",
    "    # now the output should have shape (1, 1, 100)\n",
    "\n",
    "  defocus_vector = Reshape((1,1,defocus_1hot_shape[0]))(defocus)\n",
    "    # reshape defocus vector to have shape (1, 1, defocus_input_shape)\n",
    "    # must have the same dimension shape to concatenate with the latent vector\n",
    "  latent_vector = Concatenate()([encoder, defocus_vector])\n",
    "    # now the output should have shape (1,1,100+defocus_1hot_shape) now\n",
    "\n",
    "  # add first blow-up decoder layer\n",
    "  decoder = Conv2DTranspose(filters=f*(2**i),\n",
    "                            kernel_size=(2,2),\n",
    "                            strides=(1,1),\n",
    "                            padding='valid',\n",
    "                            use_bias=False\n",
    "                            )(latent_vector)\n",
    "  decoder = BatchNormalization(center=True, scale=True)(decoder)\n",
    "  decoder = ReLU()(decoder)\n",
    "  # now the output should have shape (2, 2, f*(2**i))\n",
    "\n",
    "  # add middle decoder layers\n",
    "  for i in range(iter-2, -1, -1 ): #iter-2 ~ 0\n",
    "    decoder = Conv2DTranspose(filters=f*(2**i),\n",
    "                              kernel_size=(4,4),\n",
    "                              strides=(2,2),\n",
    "                              padding='same',\n",
    "                              use_bias=False\n",
    "                              )(decoder)\n",
    "    decoder = BatchNormalization(center=True, scale=True)(decoder)\n",
    "    decoder = ReLU()(decoder)\n",
    "  \n",
    "  # now the output should have shape (dim/2, dim/2, f)\n",
    "\n",
    "  # add final deocder output layer\n",
    "  decoder = Conv2DTranspose(filters=1,\n",
    "                            kernel_size=(4,4),\n",
    "                            strides=(2,2),\n",
    "                            padding='same',\n",
    "                            use_bias=False\n",
    "                            )(decoder)\n",
    "  img = Dense(1, activation='tanh')(decoder)\n",
    "  # now the output should have shape (dim, dim, 1)\n",
    "\n",
    "  cond_model = Model([input_voxel,defocus], img)\n",
    "\n",
    "  return cond_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: (64, 64, 64, 2)\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 64, 64, 64, 2 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_1 (Conv3D)               (None, 32, 32, 32, 1 2048        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 32, 1 64          conv3d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 32, 32, 32, 1 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_2 (Conv3D)               (None, 16, 16, 16, 3 32768       leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 16, 16, 16, 3 128         conv3d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 16, 16, 16, 3 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_3 (Conv3D)               (None, 8, 8, 8, 64)  131072      leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 8, 8, 8, 64)  256         conv3d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 8, 8, 8, 64)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_4 (Conv3D)               (None, 4, 4, 4, 128) 524288      leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 4, 4, 4, 128) 512         conv3d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 4, 4, 4, 128) 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_5 (Conv3D)               (None, 2, 2, 2, 256) 2097152     leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 2, 2, 2, 256) 1024        conv3d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 2, 2, 2, 256) 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_6 (Conv3D)               (None, 1, 1, 1, 100) 204800      leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 1, 1, 1, 100) 0           conv3d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 9)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 1, 100)    0           leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1, 1, 9)      0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1, 1, 109)    0           reshape_1[0][0]                  \n",
      "                                                                 reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 2, 2, 256)    111616      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 2, 2, 256)    1024        conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 2, 2, 256)    0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 4, 4, 128)    524288      re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 4, 4, 128)    512         conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 4, 4, 128)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 8, 8, 64)     131072      re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 8, 8, 64)     256         conv2d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 8, 8, 64)     0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 16, 16, 32)   32768       re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 32)   128         conv2d_transpose_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 16, 16, 32)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTrans (None, 32, 32, 16)   8192        re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 16)   64          conv2d_transpose_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_5 (ReLU)                  (None, 32, 32, 16)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTrans (None, 64, 64, 1)    256         re_lu_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64, 64, 1)    2           conv2d_transpose_6[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 3,804,290\n",
      "Trainable params: 3,802,306\n",
      "Non-trainable params: 1,984\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cond_model = conditional_model(sample_shape)\n",
    "cond_model.compile(loss='mean_squared_error',\n",
    "                   optimizer=keras.optimizers.Adam(lr=0.001),\n",
    "                   metrics=[psnr_metric,mse_metric])\n",
    "print(\"input shape:\", sample_shape)\n",
    "cond_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13496,
     "status": "ok",
     "timestamp": 1619556188303,
     "user": {
      "displayName": "Chuan Chen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjGNZ_BC0raiaLxFCSgR1dppBgMgjY4TPSe81Bz=s64",
      "userId": "01488084844237739692"
     },
     "user_tz": 240
    },
    "id": "g0YwgwP9qZdE",
    "outputId": "1a6819f0-99ba-4dde-f405-62445c3dc9c2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "1405/1880 [=====================>........] - ETA: 17s - loss: 0.0086 - psnr_metric: 21.6130 - mse_metric: 0.0086"
     ]
    }
   ],
   "source": [
    "# Fit with DataGenerators\n",
    "history = cond_model.fit(train_generator,\n",
    "          validation_data = valid_generator,\n",
    "          epochs = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.figure(figsize=[8,8])\n",
    "\n",
    "plt.plot(history.history['mse_metric'])\n",
    "plt.plot(history.history['val_mse_metric'])\n",
    "plt.title('Loss curve')\n",
    "plt.ylabel('MSE loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for PSNR\n",
    "plt.figure(figsize=[8,8])\n",
    "\n",
    "plt.plot(history.history['psnr_metric'])\n",
    "plt.plot(history.history['val_psnr_metric'])\n",
    "plt.title('PSNR curve')\n",
    "plt.ylabel('PSNR')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(history2['val_psnr_metric']))\n",
    "print(np.max(history.history['val_psnr_metric']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '../../models/model_050221/'\n",
    "model_file = 'model_32x32_200epochs_050121.pth'\n",
    "\n",
    "# Save model\n",
    "cond_model.save(model_dir+model_file)\n",
    "\n",
    "# Save history file\n",
    "\n",
    "hist_file = \"history.pkl\"\n",
    "with open(model_dir+'history.pkl', 'wb') as f:\n",
    "    pickle.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '../../models/model_050121/'\n",
    "model_file = 'model_32x32_200epochs_050121.pth'\n",
    "# Loading history\n",
    "with open(model_dir+'history.pkl', 'rb') as f:\n",
    "    history2 = pickle.load(f)\n",
    "history2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = train_generator[80]\n",
    "preds = cond_model.predict(X)\n",
    "k = 5\n",
    "plt.figure(figsize=[7,20])\n",
    "for i in range(k):\n",
    "    se = np.linalg.norm(y[i,:,:,0] - preds[i,:,:,0])\n",
    "    plt.subplot(k,2,i*2+1)\n",
    "    if i == 0:\n",
    "        plt.title(\"Predicted\")\n",
    "    plt.imshow(preds[i,:,:,0],cmap='Greys')\n",
    "    plt.ylabel(\"Defocus: {}nm\".format(np.argmax(X[1][i])))\n",
    "    plt.xlabel(\"Squared Error: {:2.6f}\".format(se))\n",
    "    plt.subplot(k,2,i*2+2)\n",
    "    if i == 0:\n",
    "        plt.title(\"Actual\")\n",
    "    plt.imshow(y[i,:,:,0],cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('cond_model_100epochs_042821.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=2\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(preds[k,:,:,0],cmap='Greys')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(y[k],cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-IfungIzHR0F"
   },
   "source": [
    "# load data - original size\n",
    "\n",
    "can't do it right now, takes up too much memory and kills session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LKcG0lyiHUJi"
   },
   "outputs": [],
   "source": [
    "with open(r\"em_data/X_list_840x540x980.pkl\", 'rb') as f:\n",
    "  X_3d = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L4G97Z5YOUNL"
   },
   "outputs": [],
   "source": [
    "with open(r\"em_data/y_list_840x540.pkl\", 'rb') as f:\n",
    "  y_2d = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37118,
     "status": "ok",
     "timestamp": 1615399184174,
     "user": {
      "displayName": "Chuan Chen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjGNZ_BC0raiaLxFCSgR1dppBgMgjY4TPSe81Bz=s64",
      "userId": "01488084844237739692"
     },
     "user_tz": 300
    },
    "id": "9vXJaT5DHnGE",
    "outputId": "b7788189-2174-4ce7-9c66-7e9cc7f10350"
   },
   "outputs": [],
   "source": [
    "print(len(X_3d))\n",
    "print(type(X_3d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37112,
     "status": "ok",
     "timestamp": 1615399184174,
     "user": {
      "displayName": "Chuan Chen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjGNZ_BC0raiaLxFCSgR1dppBgMgjY4TPSe81Bz=s64",
      "userId": "01488084844237739692"
     },
     "user_tz": 300
    },
    "id": "MWpLMQ2gNj2p",
    "outputId": "e8ef065b-9144-4110-b2ed-5e909312a57a"
   },
   "outputs": [],
   "source": [
    "print(len(y_2d))\n",
    "print(type(y_2d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UdyXeKXjOzvX"
   },
   "outputs": [],
   "source": [
    "# every element in the X_3d list is a sparse matrix, convert it to a 3D numpy array\n",
    "# takes too large of a memory, only process the first 1 matrix\n",
    "X_array = []\n",
    "for i in range(1):\n",
    "  X_array.append(sparse.COO.todense(X_3d[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fs0UjOZ7PAcb"
   },
   "outputs": [],
   "source": [
    "# change X to be an array of input shape (#_samples, x, y, z)\n",
    "# change y to be an array of output shape (#_samples, x, y)\n",
    "\n",
    "X_train = np.zeros(shape=(1, 840, 540, 980))\n",
    "X_train[0] = X_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XftRh4LZO7u5"
   },
   "outputs": [],
   "source": [
    "np.unique(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LPWNJsoCSQ6i"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9063a9f0e032>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMJolVUPbjW6WA3J0AOG64t",
   "collapsed_sections": [],
   "name": "1.2_cnn on 3d voxel data 2 channel.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
