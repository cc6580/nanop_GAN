{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import itertools\n",
    "import glob\n",
    "import numpy as np\n",
    "import sparse\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_voxel_grid(cif_file,voxel_count, max_dims, atoms_used=['Ce','O']):\n",
    "    '''\n",
    "    Voxelize the a single .cif file. Automatically detects which of 2 .cif file formats is used.\n",
    "    Inputs:\n",
    "    cif_file - str, path to .cif file\n",
    "    voxel_count - list [x,y,z] or scalar if all same, number of voxels per side.\n",
    "    max_dims - list [x,y,z] of max dimensions across structures. Used to set appropriate\n",
    "               grid depth in z dimension, which varies across structures.\n",
    "    atoms_used - list, indicates which atoms to include \n",
    "    \n",
    "    Outputs:\n",
    "    grid - 3D numpy array [voxel_size_x,voxel_size_y,voxel_size_z] \n",
    "           where values indicate number of atoms centered in the voxel\n",
    "    coor - numpy array [n_atoms,3] of coordinates of each atom\n",
    "    atom_type numpy array [n_atoms] of atom type\n",
    "    \n",
    "    NOTE: coor and atom_type include all atoms, not just those in atoms_used.\n",
    "    '''\n",
    "    # Read the .cif file\n",
    "    f = open(cif_file)\n",
    "    y = f.readlines()\n",
    "\n",
    "    # Box dimensions\n",
    "    # Extract '_cell_length_c' from .cif file. This length varies for each structure.\n",
    "    increm = 0\n",
    "    # try-except accounts for new .cif format where cell lengths start on line 3\n",
    "    try:\n",
    "        x_dim = float(y[2].split('  ')[-1])\n",
    "    except ValueError:\n",
    "        increm = 1\n",
    "        x_dim = float(y[2+increm].split('  ')[-1])\n",
    "    y_dim = float(y[3+increm].split('  ')[-1])\n",
    "    z_dim = float(y[4+increm].split('  ')[-1])\n",
    "\n",
    "    # Extract the atom locations\n",
    "    if len(y[15].split(\"  \")) < 4:\n",
    "\n",
    "        # for .cif files from ASU_April_21\n",
    "        if len(y[23].split(\"  \")) < 4:\n",
    "            z=np.array([x.split(\"  \") for x in y[26:]])\n",
    "            coor = np.array([[float(y) for y in x] for x in z[:,4:7]])\n",
    "            atom_type = np.array([x.split(\" \")[0] for x in z[:,1]])\n",
    "\n",
    "        # for .cif files from models_wedge_cif and models_wedge_cif_2\n",
    "        else:\n",
    "            z=np.array([x.split(\"  \") for x in y[23:-1]])\n",
    "            coor = np.array([[float(y) for y in x] for x in z[:,2:5]])\n",
    "            atom_type = np.array([x.split(\" \")[0] for x in z[:,1]])\n",
    "\n",
    "    # for .cif files from models_cif\n",
    "    elif len(y[15].split(\"  \")) == 4:\n",
    "        z = np.array([x.split(\"  \") for x in y[15:]]) \n",
    "        coor = np.array([[float(y) for y in x] for x in z[:,1:]]) \n",
    "        atom_type = z[:,0]\n",
    "\n",
    "    # Voxelize\n",
    "    # .cif describes a 1x1x1 box, so voxel_count of 0.25 would create 4 voxels per dimension (4^3 total voxels)\n",
    "    if type(voxel_count) == list:\n",
    "        voxel_count_x,voxel_count_y,voxel_count_z = voxel_count\n",
    "    elif (type(voxel_count) == int) or (type(voxel_count) == float):\n",
    "        voxel_count_x = voxel_count\n",
    "        voxel_count_y = voxel_count\n",
    "        voxel_count_z = voxel_count\n",
    "        \n",
    "    # grid has number of channels equal to number of atom types in lattice\n",
    "    num_atoms = len(atoms_used)\n",
    "    atom_mapping = {at:i for i,at in enumerate(atoms_used)}\n",
    "    grid = np.zeros([voxel_count_x,voxel_count_y,voxel_count_z,num_atoms])\n",
    "\n",
    "    # Normalize coor for axis lengths\n",
    "    coor = coor*np.array([x_dim,y_dim,z_dim])/np.array(max_dims)\n",
    "    \n",
    "    for i,atom in enumerate(coor):\n",
    "        if atom_type[i] in atoms_used:\n",
    "            x = int(np.floor(atom[0]*voxel_count_x))\n",
    "            y = int(np.floor(atom[1]*voxel_count_y))\n",
    "            z = int(np.floor(atom[2]*voxel_count_z))\n",
    "            grid[x,y,z,atom_mapping[atom_type[i]]] += 1\n",
    "    grid = sparse.COO.from_numpy(grid)\n",
    "    return grid, coor, atom_type\n",
    "\n",
    "# Determine max z length\n",
    "def max_z_value(dir_header, dir_list_cif):\n",
    "\n",
    "    cif_files = []\n",
    "\n",
    "    for dirr in dir_list_cif:\n",
    "        cif_files.extend(glob.glob(dir_header+dirr+'/Ce*.cif'))\n",
    "\n",
    "    x_list,y_list,z_list = [],[],[]\n",
    "\n",
    "    for cf in cif_files:\n",
    "        f = open(cf)\n",
    "        y = f.readlines()\n",
    "        # increm accounts for new format .cif files\n",
    "        increm = 0\n",
    "        try:\n",
    "            x_list.append(float(y[2].split('  ')[-1]))\n",
    "        except ValueError:\n",
    "            increm = 1\n",
    "            x_list.append(float(y[2+increm].split('  ')[-1]))\n",
    "        y_list.append(float(y[3+increm].split('  ')[-1]))\n",
    "        z_list.append(float(y[4+increm].split('  ')[-1]))\n",
    "\n",
    "    return [np.max(x_list),np.max(y_list),np.max(z_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_data(dir_header, dir_list_cif, dir_list_img, voxel_count, \n",
    "                           atoms_used, defocus_used, im_size = 256):\n",
    "    '''\n",
    "    Generates pairs of voxel grid (X) and image (y) as well as defocus parameter and filenames, for training\n",
    "    3D grid -> image model.\n",
    "    \n",
    "    Inputs:\n",
    "    dir_list_cif - list of directories containing .cif files, relative path from current directory\n",
    "    dir_list_img - list of directories containing .yif files, relative path from current directory\n",
    "    voxel_count - scalar int indicating desired voxels per grid dimension\n",
    "    atoms_used - List of strings indicating which atom types (e.g. ['O', 'Ce']) to include. \n",
    "    defocus_used - List of ints indicating which defocus values to include. If set to 1, all values are used.\n",
    "    im_size - 2-tuple of ints indicating desired pixels per image dimension (X,Y)\n",
    "    \n",
    "    Outputs:\n",
    "    X_list - List of [grid, atom_type] lists for each .cif-.tif pair used. \n",
    "              grid is a [voxel_size^3] np.array with counts of atoms in each voxel\n",
    "              atom_type is a np.array of strings for each atom's periodic symbol\n",
    "                \n",
    "    y_list - List of images, one for each entry in X_list. image is a [im_size[0],im_size[1]] np.array of pixel values.\n",
    "              image created by cropping input to square then resizing to im_size in PIL.\n",
    "    defocus_list - List of ints, defocus parameter for each sample \n",
    "    img_file_list - List of image filenames for each sample.\n",
    "    \n",
    "    '''\n",
    "    # Calculate largest z value\n",
    "    max_dims = max_z_value(dir_header,dir_list_cif)\n",
    "    \n",
    "    cif_files = []\n",
    "    for dirr in dir_list_cif:\n",
    "        cif_files.extend(glob.glob(dir_header+dirr+'/Ce*.cif'))\n",
    "\n",
    "\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    defocus_list = []\n",
    "    img_file_list = []\n",
    "\n",
    "    for cif in cif_files:\n",
    "        # Create voxel grid from .cif file \n",
    "        X, coor, atom_type = create_voxel_grid(cif,voxel_count, max_dims, atoms_used=atoms_used)\n",
    "\n",
    "        # Find all associated images\n",
    "        img_files = []\n",
    "        [img_files.extend(glob.glob((dir_header+dirr+cif[cif.find(\"/\",len(dir_header)+5):-4]+'*.tif').replace('[','?').replace(']','?'))) for dirr in dir_list_img]\n",
    "        # find starts after the dir_header so it catches the last /\n",
    "        # Filter out 'def' files\n",
    "        img_files_clean = []\n",
    "        for i,im_f in enumerate(img_files):\n",
    "            if im_f.find(\"_def_\") < 0:\n",
    "                img_files_clean.append(im_f)\n",
    "        img_files = img_files_clean        \n",
    "        # Filter by Defocus value\n",
    "        nm_loc = [im_f.find(\"nmDefocus\") for im_f in img_files]\n",
    "        \n",
    "#         defocus_cif = [abs(int(im_f[loc-2:loc])) for im_f,loc in zip(img_files,nm_loc)]\n",
    "        defocus_cif = []\n",
    "        for im_f,loc in zip(img_files,nm_loc):\n",
    "            if im_f[loc-2:loc-1] == '_':\n",
    "                defocus_cif.append(abs(int(im_f[loc-1:loc])))\n",
    "            else:\n",
    "                defocus_cif.append(abs(int(im_f[loc-2:loc])))\n",
    "            \n",
    "    \n",
    "        if defocus_used == 1:\n",
    "            defocus_used = set(defocus_cif)\n",
    "\n",
    "        #X_count counts the number of images for each .cif file, to replicate the voxel that many times\n",
    "        X_count = 0\n",
    "        # Collect image data\n",
    "        for defoc,image in zip(defocus_cif,img_files):\n",
    "            if defoc in defocus_used:\n",
    "                X_count +=1\n",
    "                im_data=np.array(Image.open(image).resize((im_size[0],im_size[1])))\n",
    "                y_list.append(im_data)\n",
    "                defocus_list.append(defoc)\n",
    "                img_file_list.append(image)    \n",
    "\n",
    "        # Make training pairs for each defocus value in defocus_used\n",
    "        X_list.extend(itertools.repeat(X,X_count)) # Probably move this so it can be repeated for various defocus values\n",
    "    return X_list, y_list, defocus_list, img_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "# dir_header = '../../em_data/'\n",
    "# dir_list_cif = ['models_cif','models_wedge_cif','models_wedge_cif_2']\n",
    "# dir_list_img = ['all_images','all_images_wedge','all_images_wedge_2']\n",
    "\n",
    "dir_header = 'em_data/'\n",
    "dir_list_cif = ['1at/CIF','2at/CIF','2at_2/CIF','3at/CIF','3at_2/CIF','4at/CIF','4at_2/CIF',\n",
    "                '5at/CIF','5at_2/CIF','6at/CIF','6at_2/CIF','7at/CIF','7at_2/CIF','8at/CIF',\n",
    "                '8at_2/CIF','9at/CIF','9at_2/CIF','10at/CIF','10at_2/CIF']\n",
    "dir_list_img = ['1at','2at','2at_2','3at','3at_2','4at','4at_2','5at','5at_2','6at','6at_2',\n",
    "                '7at','7at_2','8at','8at_2','9at','9at_2','10at','10at_2']\n",
    "\n",
    "voxel_count = [84,54,98]\n",
    "im_size = [84,54]\n",
    "atoms_used=['Ce','O']\n",
    "defocus_used = 1 # list defocus values to use, or set =1 to use all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-34077f8b802f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m X_list, y_list, defocus_list, img_file_list = generate_training_data( \\\n\u001b[0m\u001b[1;32m      2\u001b[0m                             dir_header, dir_list_cif, dir_list_img, voxel_count, atoms_used, defocus_used, im_size)\n",
      "\u001b[0;32m<ipython-input-3-d45aae13e8a6>\u001b[0m in \u001b[0;36mgenerate_training_data\u001b[0;34m(dir_header, dir_list_cif, dir_list_img, voxel_count, atoms_used, defocus_used, im_size)\u001b[0m\n\u001b[1;32m     25\u001b[0m     '''\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# Calculate largest z value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mmax_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_z_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdir_list_cif\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mcif_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-eb91c93aab30>\u001b[0m in \u001b[0;36mmax_z_value\u001b[0;34m(dir_header, dir_list_cif)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mz_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mincrem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'  '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mamax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2731\u001b[0m     \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2732\u001b[0m     \"\"\"\n\u001b[0;32m-> 2733\u001b[0;31m     return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n\u001b[0m\u001b[1;32m   2734\u001b[0m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[1;32m   2735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "X_list, y_list, defocus_list, img_file_list = generate_training_data( \\\n",
    "                            dir_header, dir_list_cif, dir_list_img, voxel_count, atoms_used, defocus_used, im_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cif_files = []\n",
    "\n",
    "for dirr in dir_list_cif:\n",
    "    cif_files.extend(glob.glob(dir_header+dirr+'/Ce*.cif'))\n",
    "cif_files\n",
    "# x_list,y_list,z_list = [],[],[]\n",
    "\n",
    "# for cf in cif_files:\n",
    "#     f = open(cf)\n",
    "#     y = f.readlines()\n",
    "#     # increm accounts for new format .cif files\n",
    "#     increm = 0\n",
    "#     try:\n",
    "#         x_list.append(float(y[2].split('  ')[-1]))\n",
    "#     except ValueError:\n",
    "#         increm = 1\n",
    "#         x_list.append(float(y[2+increm].split('  ')[-1]))\n",
    "#     y_list.append(float(y[3+increm].split('  ')[-1]))\n",
    "#     z_list.append(float(y[4+increm].split('  ')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob(dir_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"X_list_10a_2channel.pkl\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(X_list, fp)\n",
    "\n",
    "with open(\"y_list_10a_2channel.pkl\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(y_list, fp)\n",
    "\n",
    "with open(\"defocus_list_10a_2channel.pkl\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(defocus_list, fp)\n",
    "\n",
    "with open(\"img_file_list_10a_2channel.pkl\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(img_file_list, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_filled_slice(grid):\n",
    "    '''Function returns index of the last non-zero slice in the grid.'''\n",
    "    # Sum the x-y slices\n",
    "    slice_sums = grid.sum(axis=0).sum(axis=0)\n",
    "    # Identify the last non-zero slice\n",
    "    idx = max(index for index, item in enumerate(slice_sums) if item > 0)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
